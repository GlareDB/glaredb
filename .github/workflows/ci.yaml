name: GlareDB CI

on: [push, workflow_dispatch]

# Jobs:
# build -> Builds binaries. This will build and cache deps as well.
# test -> Runs tests, using cache from 'build'.
# integration -> Runs integration tests, using cache from 'build'.
#
# Cachix is used for caching.

jobs:
  build:
    name: Build and Test
    runs-on: ubuntu-latest-8-cores
    concurrency:
      group: build-ci-${{ github.ref }}
      cancel-in-progress: true

    env:
      PROTOC: 

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache
        uses: Swatinem/rust-cache@v2

      - name: Download protoc
        run: |
          wget https://github.com/protocolbuffers/protobuf/releases/download/v23.1/protoc-23.1-linux-x86_64.zip
          unzip protoc-23.1-linux-x86_64.zip -d $HOME/.protoc         

          echo "$HOME/.protoc/bin/" >> $GITHUB_PATH

      - name: Build
        run: |
          export PROTOC="$HOME/.protoc/bin/protoc"
          cargo build --bin glaredb
          cargo build --bin pgprototest
          cargo build --bin sqllogictests

      - name: Test
        run: |
          export PROTOC="$HOME/.protoc/bin/protoc"
          cargo test

      - name: Clippy
        run: |
          export PROTOC="$HOME/.protoc/bin/protoc"
          cargo clippy --all-features -- --deny warnings

      - name: Format
        run: cargo fmt --check

  integration:
    needs: build
    name: Integration tests
    runs-on: ubuntu-latest-8-cores
    concurrency:
      group: integ-ci-${{ github.ref }}
      cancel-in-progress: true

    env:
      GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_JSON }}
      GCP_PROJECT_ID: glaredb-artifacts
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      SNOWFLAKE_USERNAME: ${{ secrets.SNOWFLAKE_USERNAME }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Cache
        uses: Swatinem/rust-cache@v2

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_JSON }}

      # Setup snowsql (can't use nix coz it's unfree).
      - name: Setup snowsql
        run: |
          curl -o snowsql.bash \
            https://sfc-repo.snowflakecomputing.com/snowsql/bootstrap/1.2/linux_x86_64/snowsql-1.2.24-linux_x86_64.bash
          mkdir -p ~/bin
          SNOWSQL_DEST=~/bin SNOWSQL_LOGIN_SHELL=~/.profile bash snowsql.bash

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v1

      - name: Download testdata from GCS
        run: ./scripts/prepare-testdata.sh

      - name: SQL Logic Tests
        run: |
          # Prepare SLT (Snowflake)
          export PATH="$HOME/bin:$PATH"
          if ./scripts/files-changed-in-branch.sh \
            "scripts/prepare-testdata.sh" \
            "scripts/create-test-snowflake-db.sh" \
            "testdata/sqllogictests_datasources_common/data" \
            "testdata/sqllogictests_snowflake/data"
          then
            export SNOWFLAKE_DATABASE=$(./scripts/create-test-snowflake-db.sh)
          else
            export SNOWFLAKE_DATABASE=glaredb_test
          fi

          # Prepare SLT (BigQuery)
          if ./scripts/files-changed-in-branch.sh \
            "scripts/prepare-testdata.sh" \
            "scripts/create-test-bigquery-db.sh" \
            "testdata/sqllogictests_datasources_common/data" \
            "testdata/sqllogictests_bigquery/data"
          then
            export GCP_PROJECT_ID=glaredb-dev-playground
            export BIGQUERY_DATASET_ID=$(./scripts/create-test-bigquery-db.sh)
          else
            export BIGQUERY_DATASET_ID=glaredb_test
          fi

          # Prepare SLT (Object store)
          export GCS_BUCKET_NAME=glaredb-test
          export AWS_S3_REGION=us-east-1
          export AWS_S3_BUCKET_NAME=glaredb-test

          # Prepare SLT (Postgres)
          POSTGRES_TEST_DB=$(./scripts/create-test-postgres-db.sh)
          export POSTGRES_CONN_STRING=$(echo "$POSTGRES_TEST_DB" | sed -n 1p)
          export POSTGRES_TUNNEL_SSH_CONN_STRING=$(echo "$POSTGRES_TEST_DB" | sed -n 2p)

          # Prepare SLT (MySQL)
          MYSQL_TEST_DB=$(./scripts/create-test-mysql-db.sh)
          export MYSQL_CONN_STRING=$(echo "$MYSQL_TEST_DB" | sed -n 1p)
          export MYSQL_TUNNEL_SSH_CONN_STRING=$(echo "$MYSQL_TEST_DB" | sed -n 2p)

          # Prepare SLT (MongoDB)
          export MONGO_CONN_STRING=$(./scripts/create-test-mongo-db.sh)

          cargo run --bin sqllogictests -- -v --exclude '*/tunnels/ssh'

      - name: Protocol Tests
        run: ./scripts/protocol-test.sh
